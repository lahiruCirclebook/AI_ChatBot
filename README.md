# ğŸ“š AI Chatbot with PDF Context Retrieval

This project is a **context-aware AI chatbot** that intelligently answers questions based *only* on the content of a given PDF document. It uses **LangChain**, **Groqâ€™s Qwen model**, **Pinecone**, and **Hugging Face embeddings** to perform Retrieval-Augmented Generation (RAG) for document-based Q&A.

If a question is **out of context**, it responds with:
> â€œI donâ€™t know based on the provided context.â€

---

## ğŸš€ Demo Features

- âœ… Answers strictly based on PDF content
- ğŸ” Uses semantic search with Pinecone
- ğŸ§  Integrated Groq LLM (Qwen-QWQ-32B)
- ğŸ“„ Processes and chunks PDF content using LangChain
- ğŸ¤ Voice input support
- ğŸ”Š Text-to-speech output for bot responses
- ğŸ–¼ï¸ Modern UI with Bootstrap 4
- âš™ï¸ Flask backend with RESTful endpoint

---

## ğŸ§  Tech Stack

| Purpose         | Technology                                 |
|----------------|---------------------------------------------|
| Backend         | Flask, LangChain                           |
| Embeddings      | Hugging Face `all-MiniLM-L6-v2`            |
| Vector Store    | Pinecone                                    |
| LLM             | Groq `qwen-qwq-32b`                         |
| Frontend        | HTML, CSS, Bootstrap 4.6, jQuery, JS        |
| Voice & TTS     | Web Speech API                             |

---

## ğŸ“ Project Structure

project-root/
â”‚
â”œâ”€â”€ app.py # Main Flask application
â”œâ”€â”€ setup.py # Python package setup
â”œâ”€â”€ .env # Environment variables (PINECONE & GROQ keys)
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ helper.py # File loading, splitting, and embedding functions
â”‚ â”œâ”€â”€ prompt.py # System prompt for chat logic
â”‚
â”œâ”€â”€ static/
â”‚ â””â”€â”€ style.css # UI styles
â”‚
â”œâ”€â”€ templates/
â”‚ â””â”€â”€ index.html # Main chat UI
â”‚
â”œâ”€â”€ Data/
â”‚ â””â”€â”€ your-pdf-file.pdf # The document used as context
â””â”€â”€ research/
â””â”€â”€ trials.ipynb # Optional experiments notebook


---

## âš™ï¸ Installation & Setup

### 1. Clone the repository

```bash
git clone https://github.com/lahiruCirclebook/AI_ChatBot.git
cd AI_ChatBot

python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows

pip install -r requirements.txt

PINECONE_API_KEY=your-pinecone-key
GROQ_API_KEY=your-groq-key

python app.py
The app will be available at http://localhost:8080.

ğŸ“š How It Works
PDF files are loaded and split into text chunks using LangChain's RecursiveCharacterTextSplitter.

Chunks are embedded using Hugging Face all-MiniLM-L6-v2.

Pinecone is used to store and retrieve similar chunks.

Groq's Qwen LLM generates an answer from the top k=3 relevant chunks.

If content is irrelevant, the bot replies with a default fallback message using a custom system prompt.

ğŸ“Œ System Prompt (Used for Grounding)
"You are a highly knowledgeable and concise AI assistant specialized in answering complex questions using the provided context. ... If the context does not contain enough information, respond with: 'I don't know based on the provided context.'"

ğŸ§ª Example Questions
âœ… "What is a Markov Chain?"
â†’ Will return an accurate answer from the PDF.

âŒ "Tell me 4 animals"
â†’ Will return: "I don't know based on the provided context."

