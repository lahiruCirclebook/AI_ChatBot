{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d45aff5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\AI_ChatBot\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f135293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4153b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\AI_ChatBot'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f676fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1785637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract data from the pdf\n",
    "def load_pdf_file(data):\n",
    "    loader=DirectoryLoader(\n",
    "        data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents=loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f1cd28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf_file(data='Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f7e751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9caf2293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2371\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8126e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ccf82ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the embedding from hugging face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf723493",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97c608c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.015530286356806755, 0.14416012167930603, -0.003489758586511016, 0.04087614268064499, -0.058465588837862015, 0.029729219153523445, 0.05767727643251419, -0.004789259750396013, -0.017884263768792152, -0.031429361552000046, 0.08618224412202835, -0.029026849195361137, -0.03918154910206795, -0.03882989287376404, 0.058014724403619766, -0.003082044655457139, -0.0811605453491211, -0.011851095594465733, -0.09150673449039459, -0.05118604004383087, 0.1090053915977478, 0.02310873754322529, 0.009349126368761063, 0.0028737829998135567, -0.06266666948795319, -0.06153743341565132, 0.09525725990533829, -0.018649205565452576, 0.0822243019938469, -0.06310760974884033, -0.008218184113502502, 0.06347844004631042, 0.0397406667470932, -0.0024888531770557165, -0.042481016367673874, 0.1324295550584793, 0.042675700038671494, -0.002224695635959506, 0.07782162725925446, -0.030601365491747856, 0.00992884486913681, -0.03769165277481079, 0.027743985876441002, 0.030646437779068947, -0.013506635092198849, -0.055897023528814316, -0.03630296140909195, -0.018036894500255585, -0.03912092745304108, -0.06377953290939331, -0.13796167075634003, 0.009525137953460217, 0.033211518079042435, 0.04621894657611847, -0.014791322872042656, -0.022735020145773888, -0.02686927653849125, -0.039047982543706894, 0.0684809610247612, -0.012164097279310226, 0.0009802829008549452, 0.060381341725587845, -0.06499979645013809, 0.019612405449151993, 0.05708933621644974, -0.09572619944810867, 0.0824916884303093, -0.037353627383708954, -0.017485449090600014, 0.011123910546302795, -0.04983535036444664, -0.020747896283864975, -0.05468188598752022, 0.0018748296424746513, -0.05889466777443886, -0.09732233732938766, -0.015493758954107761, -0.05877750739455223, -0.018025802448391914, -0.041527457535266876, 0.007871722802519798, 0.07058902829885483, 0.01130693033337593, 0.06237243115901947, 0.01034483127295971, 0.042077381163835526, -0.017360208556056023, -0.03630296140909195, 0.058611806482076645, -0.036630433052778244, 0.0023370354901999235, -0.03405853733420372, -0.018353188410401344, -0.01674620993435383, -0.044668830931186676, 0.022274799644947052, 0.00251281401142478, 0.02112833969295025, 0.06236416473984718, 0.0785040557384491, 0.03446843475103378, -0.016811760142445564, -0.019261697307229042, 0.0245100948959589, -0.150922954082489, -0.06607923656702042, 0.009615205228328705, 0.016032468527555466, 0.030833914875984192, -0.007298517040908337, -0.07298170030117035, -0.06510459631681442, -0.023620400577783585, -0.06776852160692215, 0.028973031789064407, -0.0016708184266462922, 0.08008638024330139, 0.03613841161131859, -0.08227493613958359, -0.03946240246295929, -0.061988238245248795, -0.012675482779741287, -0.012562956660985947, -0.027354737743735313, -0.05870211869478226, -0.10490360110998154, -0.06375979632139206, 1.150398349992823e-34, 0.07339967042207718, -0.004858567379415035, -0.01823747716844082, 0.011021344922482967, -0.09589848667383194, -0.05238761380314827, -0.007051067426800728, 0.00694843428209424, 0.021466530859470367, -0.026091987267136574, 0.03232046216726303, 0.02249644696712494, -0.038879647850990295, -0.003810255089774728, -0.02002769336104393, 0.005984132643789053, -0.020627791061997414, 0.00888841599225998, 0.0023277346044778824, 0.01464906707406044, 0.022887147963047028, 0.03678988665342331, 0.002174742752686143, -0.025315115228295326, 0.09973561018705368, -0.019903162494301796, 0.09341148287057877, -0.02131950668990612, -0.00208705710247159, 0.05078738555312157, 0.051707055419683456, -0.004757214337587357, -0.014000874012708664, -0.04355143383145332, 0.05119594559073448, 0.08981727063655853, -0.022988509386777878, -0.011114987544715405, -0.04846698418259621, -0.07164017856121063, 0.025762615725398064, 0.04542069137096405, 0.0654657706618309, -0.0010943221859633923, -0.0016491725109517574, 0.09485460817813873, -0.039487503468990326, -0.02110373228788376, 0.0018390410114079714, 0.02725069411098957, -0.02437995746731758, 0.04984182119369507, -0.09011491388082504, -0.014966520480811596, 0.06022905930876732, -0.018277229741215706, -0.0713200718164444, 0.03127868101000786, 0.04428998380899429, 0.03348440304398537, 0.0031970057170838118, -0.096554234623909, -0.06706783920526505, 0.05967189744114876, -0.07541260868310928, -0.06201557815074921, -0.006506717763841152, -0.07037032395601273, 0.007427942473441362, -0.053850818425416946, -0.06713420152664185, -0.024182023480534554, -0.09903741627931595, 0.07210531830787659, -0.09923052787780762, 0.0028799488209187984, -0.053998179733753204, -0.04230848327279091, -0.027621710672974586, 0.042693156749010086, -0.045544348657131195, 0.03680820390582085, 0.04135289043188095, 0.05082063749432564, 0.043040916323661804, -0.030909638851881027, 0.06763345003128052, -0.0725044384598732, -0.02529286779463291, -0.0292559415102005, -0.012957686558365822, 0.047121915966272354, 0.10127986967563629, -0.07741338759660721, -0.011347055435180664, -2.3713183254290695e-33, 0.0220798309892416, 0.015506933443248272, -0.03779152035713196, -0.02119557000696659, 0.01362734567373991, 0.020445941016077995, -0.010732234455645084, 0.06083647906780243, -0.037966303527355194, -0.01844695955514908, -0.022310558706521988, -0.04645638167858124, 0.035954203456640244, 0.012727033346891403, -0.0858771950006485, -0.0036690058186650276, 0.0892934799194336, 0.01877650059759617, 0.006124800071120262, 0.05021144822239876, 0.017625175416469574, 0.11801149696111679, -0.10288786143064499, -0.03914522007107735, -0.014027031138539314, 0.05308067798614502, 0.05763709545135498, 0.02282635122537613, -0.08403144031763077, 0.03884836658835411, 0.041880201548337936, -0.03335433080792427, -0.11142222583293915, 0.008689120411872864, -0.07380765676498413, -0.0043077957816421986, 0.08760297298431396, 0.0018204563530161977, -0.031351830810308456, -0.0029188802000135183, 0.029851160943508148, 0.007552961353212595, 0.0655144527554512, 0.06289616972208023, -0.04381512105464935, 0.010699331760406494, 0.06079994887113571, 0.045929133892059326, -0.010897866450250149, -0.039948720484972, 0.009175948798656464, -0.0395723320543766, 0.03157235309481621, -0.08512938767671585, 0.032817721366882324, 0.01602919213473797, -0.02209991216659546, -0.02876908890902996, 0.07478943467140198, -0.09719549864530563, -0.020181728526949883, 0.05400721728801727, 0.012126164510846138, 0.0803343653678894, 0.013462785631418228, 0.023014552891254425, 0.06645117700099945, 0.013409887440502644, 0.05509233474731445, -0.08472926169633865, 0.011228569783270359, -0.06621517241001129, -0.02557290717959404, 0.05396850407123566, -0.05182745307683945, 0.02551666647195816, -0.03119691275060177, 0.017351776361465454, 0.03137949854135513, 0.05123729258775711, 0.023251909762620926, -0.03069913387298584, -0.06352050602436066, 0.022958066314458847, 0.05522501468658447, -0.011587195098400116, 0.01601838879287243, -0.04790905490517616, 0.020413199439644814, -0.02442372962832451, -0.03334593027830124, -0.018256735056638718, -0.0313909575343132, 0.015530780889093876, 0.07211989164352417, -2.201067417217928e-08, -0.01364931557327509, -0.07342765480279922, -0.05059010908007622, -0.021056052297353745, -0.005111058708280325, 0.023152077570557594, 0.07537536323070526, 0.04167284071445465, -0.040877990424633026, 0.0509120374917984, 0.05515566095709801, 0.1465289145708084, 0.009645086713135242, 0.01834377646446228, 0.06034993752837181, -0.009273958392441273, 0.04921775311231613, 0.01560867391526699, -0.06431650370359421, -0.06137044355273247, 0.11050059646368027, 0.028346296399831772, 0.004304435104131699, 0.001598761766217649, -0.04981250315904617, 0.07455459982156754, -0.029988005757331848, 0.027843816205859184, -0.10410068184137344, -0.007864456623792648, 0.0410623624920845, 0.0885363221168518, -0.031490594148635864, 0.0009371081832796335, -0.0008402540115639567, 0.030089568346738815, -0.05506590008735657, -0.015951145440340042, 0.0507330521941185, -0.046119287610054016, 0.04095227271318436, 0.02885117195546627, 0.0689917504787445, 0.06079963594675064, 0.07067050784826279, -0.03808203712105751, -0.006153070367872715, 0.025453902781009674, 0.006497699301689863, -0.03233487159013748, -0.047184959053993225, -0.015531206503510475, 0.0708211287856102, -0.0032825442031025887, -0.05310339108109474, 0.012550369836390018, 0.030466197058558464, 0.04854820668697357, -0.08234512805938721, -0.03971395641565323, 0.22790385782718658, -0.008802756667137146, -0.01894836686551571, -0.01293402723968029]\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query('hi chandima')\n",
    "print(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37304863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "787c2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "GROQ_API_KEY = os.environ.get('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4c27da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"aichatbot\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"aichatbot-ano5e1g.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 384,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"aichatbot\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "30f8a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
    "os.environ['GROQ_API_KEY'] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16122f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embed each chunks into pinecone index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e554c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load existing index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2a900d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x1f2011ad6d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac1f65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever =  docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87744af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"what is Hidden Markov Models?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b64b2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0b071a65-2737-4380-a623-10f8df17584f', metadata={'creationdate': '', 'creator': 'PyPDF', 'moddate': '2024-09-19T22:03:01+00:00', 'page': 74.0, 'page_label': '75', 'producer': 'Pdftools SDK', 'source': 'Data\\\\Artificial Intelligence.pdf', 'total_pages': 533.0}, page_content='3.3 Hidden Markov Models  Hidden Markov Models (HMMs) are extremely common in the ML analysis of sequential data that has a dependence on time. Typically, a model will be able to explain a sequence and predict or generate new sequences. The techniques are most at home with Natural Language Processing (NLP) and with handwriting recognition, speech recognition, and biological informatics.  With an HMM there are two collections of probabilities. In the background, there is a probabilistic Markov'),\n",
       " Document(id='bbfbdd0d-66db-4767-98fb-6fe8c02e8e4a', metadata={'creationdate': '', 'creator': 'PyPDF', 'moddate': '2024-09-19T22:03:01+00:00', 'page': 488.0, 'page_label': '489', 'producer': 'Pdftools SDK', 'source': 'Data\\\\Artificial Intelligence.pdf', 'total_pages': 533.0}, page_content='It is a memoryless model. It ‘knows’ the state that it is in, but ‘knows’ nothing of the states before that. The child’s game Snakes and Ladders is an example of a Markov process.'),\n",
       " Document(id='6db251de-dc88-46b0-b64c-8d432e56825b', metadata={'creationdate': '', 'creator': 'PyPDF', 'moddate': '2024-09-19T22:03:01+00:00', 'page': 74.0, 'page_label': '75', 'producer': 'Pdftools SDK', 'source': 'Data\\\\Artificial Intelligence.pdf', 'total_pages': 533.0}, page_content=\"Markov Chain or Process as explained above. But some, or all, of the states of this Markov Process are hidden (and unseeable directly by observers). However, the hidden states 'emit' observations which can be seen or observed. These emissions of observations are themselves governed by probabilities relating them to the hidden states. An example might help with understanding the set-up. Suppose we are interested in the sequences of year-on-year climate values in New Zealand from a thousand years\")]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aaaa14da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"qwen-qwq-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2142124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a highly knowledgeable and concise AI assistant specialized in answering complex questions \"\n",
    "    \"using the provided context. Carefully analyze the retrieved context to construct an accurate and helpful response.\\n\\n\"\n",
    "    \"Guidelines:\\n\"\n",
    "    \"- Base your answer strictly on the retrieved context below. Do not rely on prior knowledge.\\n\"\n",
    "    \"- If the context does not contain enough information, respond with: 'I don't know based on the provided context.'\\n\"\n",
    "    \"- Limit your response to a maximum of **three well-structured sentences**.\\n\"\n",
    "    \"- Be clear, precise, and avoid unnecessary elaboration.\\n\\n\"\n",
    "    \"Context:\\n{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbb8ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "984f2a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "Okay, let's tackle the question \"what is the dog\" based on the provided context. First, I need to check the context given. The user provided a lengthy text about self-supervised learning, examples like spam detection, dog breeds (poodle, beagle, pug), and references to how context and previous dialogues help in determining answers. The example with Dan Bobrow shows that sometimes answers are references, not statements.\n",
      "\n",
      "The question is straightforward: \"what is the dog\". The context mentions that in a model identifying dog breeds, the classes could be poodle, beagle, pug, etc. However, the context doesn't provide any specific information about the dog in question. The example given relates to a reservation name, but that's not about dogs. Since there's no further details in the context about a specific dog or its description, I can't determine an answer from the provided text. The user might be expecting a breed, but without more context, the answer isn't here.\n",
      "</think>\n",
      "\n",
      "I don't know based on the provided context.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is the dog\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
